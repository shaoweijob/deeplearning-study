# coding=utf-8
import tensorflow as tf
'''
    创建了一个包含两幅图像的图像批数据。
    每幅图像的高为2个元素，宽为3个元素，且颜色空间为RGB。
    执行后的输出的维度所对应含义如下：
        d1: 图像数量
        d2: 图像高度
        d3: 图像宽度
        d4: 颜色通道数量
'''
image_batch = tf.constant([
    [   # image 1:
       [[0, 255, 0], [0, 255, 0], [0, 255, 0]],
        [[0, 255, 0], [0, 255, 0], [0, 255, 0]]
    ],
    [   # image 2:
       [[0, 0, 255], [0, 0, 255], [0, 0, 255]],
        [[0, 0, 255], [0, 0, 255], [0, 0, 255]]
    ]
])
print image_batch.get_shape()
'''
    每个像素的索引都会映射到图像的宽和高两个维度上。
    若要获取第一幅图像的第一个像素，需要用下列方式访问每一个维度。
'''

with tf.Session() as sess:
    print sess.run(image_batch)[0][0][0]

'''
    一种常见的方法：
        创建一些与上述image_batch实例相类似的假数据对CNN的输入和输出进行测试。
        这种简化的输入会使诊断和调试一些简单问题更加容易。简化调试过程非常重要，因为CNN架构极为复杂，训练经常需要耗费数日。
    
    CNN的第一个复杂性在于卷积层的原理上。任何图像被加载和处理后，卷积层通常是网络的第一层。
    第一个卷积层非常重要。因为它简化网络的其余部分，并用于调试。
'''

'''
    卷积：
        从名称可以看出，卷积运算是卷积神经网络的重要组成。
        CNN与各种模式精确匹配的能力可归功于卷积运算的使用。
    
    TF卷积：
        
'''

'''
    卷积核：
        重要术语，也称为权值、滤波器、卷积矩阵、模板。
        本任务与计算机视觉相关，使用术语"卷积核"显得十分有用,因为这意味着将它视为图像卷积核。
        在TF中，这个参数被命名为filter，相应的权值可以从训练中学习到。
        filter参数中不同权值的数量决定了需要学习的卷积核的数量。
'''
input_batch = tf.constant([
    [   # input 1
        [[0.0],[1.0]],
        [[2.0],[3.0]]
    ],
    [   # input 2
        [[2.0],[4.0]],
        [[6.0],[8.0]]
    ]
])
kernel = tf.constant([
    [
        [[1.0, 2.0]]
    ]
])
conv2d = tf.nn.conv2d(input_batch, kernel, strides=[1, 1, 1, 1], padding="SAME")

with tf.Session() as sess:
    print sess.run(conv2d)